var documenterSearchIndex = {"docs":
[{"location":"10-tutorial/#Tutorial","page":"Tutorial","title":"Tutorial","text":"","category":"section"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"Pages = [\"10-tutorial.md\"]\nDepth = [2, 3]","category":"page"},{"location":"10-tutorial/#Getting-Started","page":"Tutorial","title":"Getting Started","text":"","category":"section"},{"location":"10-tutorial/#Input-files","page":"Tutorial","title":"Input files","text":"","category":"section"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"We use DuckDB as the database backend for the input data of the profiles. The input data must be in a long table format with at least the columns year, profile_name, timestep, and value. Extra columns such as scenario are allowed. These defaults values are configurable by passing a ProfilesTableLayout to cluster!. See the Using a Custom Layout section for an example of how to use a custom layout.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"For this tutorial we will use the profiles file available in the TulipaClustering repository.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"In this example the profiles are in a CSV file, but you can also load them from other sources (e.g., Parquet, Excel, etc.) using DuckDB's readers.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"using DataFrames, DuckDB\n\n# change the following path to your file location\nprofiles_file = joinpath(@__DIR__,\"../../test/inputs/EU/profiles.csv\")\n\nconnection = DBInterface.connect(DuckDB.DB)\nDuckDB.query(\n  connection,\n  \"\"\"\n  CREATE TABLE profiles AS\n  SELECT * FROM read_csv('$profiles_file');\n  \"\"\",\n)\n\n# helper function to query the DuckDB tables in the connection\nnice_query(str) = DuckDB.query(connection, str) |> DataFrame\n\n# show the tables in the connection using the helper function\nnice_query(\"SHOW tables\")","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"And here we can have a look at the first rows of profiles:","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"nice_query(\"FROM profiles LIMIT 10\")","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"Let's explore the first 10 unique profile names in the profiles table:","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"nice_query(\"\"\"\n    SELECT DISTINCT profile_name\n    FROM profiles\n    ORDER BY profile_name\n    LIMIT 10\n\"\"\")","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"And finally, we can use nice_query to filter the profiles and plot them. For example, here we filter and plot the profiles in the Netherlands (i.e., those starting with NED_) and plot only a sample with the profiles for the first week of the year:","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"using Plots\n\ndf = nice_query(\"\"\"\n    SELECT *\n    FROM profiles\n    WHERE profile_name LIKE 'NED_%'\n    ORDER BY profile_name, timestep\n\"\"\")\n\nsample = 1:168\nplot(size=(800, 400))\nfor group in groupby(df, :profile_name)\n    name = group.profile_name[1]\n    plot!(group.timestep[sample], group.value[sample], label=name)\nend\nplot!(xlabel=\"Timestep\", ylabel=\"Value\", title=\"Profiles in the Netherlands\")","category":"page"},{"location":"10-tutorial/#Clustering","page":"Tutorial","title":"Clustering","text":"","category":"section"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"We can perform the clustering by using the cluster! function by passing the connection with the profiles table and two extra arguments (see Concepts for their deeped meaning):","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"period_duration: How long are the periods (e.g., 24 for daily periods if the timestep is hourly);\nnum_rps: How many representative periods.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"In this example we use the function cluster! with its default parameters. Section Hull Clustering with Blended Representative Periods explains the extra parameters that can be passed to the clustering function.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"Finally, it will create new output tables in the DuckDB connection that we will explore in the next section.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"After the clustering, four tables will be created in the DuckDB connection:","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"using TulipaClustering\n\nperiod_duration = 24\nnum_rps = 4\n\nfor table_name in (          # hide\n    \"rep_periods_data\",      # hide\n    \"rep_periods_mapping\",   # hide\n    \"profiles_rep_periods\",  # hide\n    \"timeframe_data\",        # hide\n)                            # hide\n    DuckDB.query(connection, \"DROP TABLE IF EXISTS $table_name\") # hide\nend                          # hide\n\nclusters = cluster!(connection, period_duration, num_rps)\n\nnice_query(\"SHOW tables\")","category":"page"},{"location":"10-tutorial/#Output-Tables","page":"Tutorial","title":"Output Tables","text":"","category":"section"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"The output tables are:","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"profiles_rep_periods contains the profiles for each RP,","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"nice_query(\"FROM profiles_rep_periods LIMIT 5\")","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"rep_periods_data contains the general informations of the RPs,","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"nice_query(\"FROM rep_periods_data LIMIT 5\")","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"rep_periods_mapping containts the weights that are use to map the RPs to the original (or base) periods,","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"nice_query(\"FROM rep_periods_mapping LIMIT 5\")","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"timeframe_data contains information about the original (or base) periods","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"nice_query(\"FROM timeframe_data LIMIT 5\")","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"You can use DuckDB to explore the results using SQL queries or export them to CSV or Parquet files using DuckDB's writers.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"For example, we can plot again the profiles in the Netherlands, but this time using the clustered profiles:","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"df = nice_query(\"\"\"\n    SELECT *\n    FROM profiles_rep_periods\n    WHERE profile_name LIKE 'NED_%'\n    ORDER BY profile_name, timestep\n\"\"\")\nrep_periods = unique(df.rep_period)\nplots = []\n\nfor rp in rep_periods\n    df_rp = filter(row -> row.rep_period == rp, df)\n    p = plot(size=(400, 300), title=\"Representative Period $rp\")\n\n    for group in groupby(df_rp, :profile_name)\n        name = group.profile_name[1]\n        plot!(p, group.timestep, group.value, label=name)\n    end\n\n    show_legend = (rp == rep_periods[1])\n    plot!(p,\n          xlabel=\"Timestep\",\n          ylabel=\"Value\",\n          xticks=0:2:period_duration,\n          xlim=(1, period_duration),\n          ylim=(0, 1),\n          legend=show_legend ? :bottomleft : false,\n          legendfontsize=6\n         )\n    push!(plots, p)\nend\n\nplot(plots..., layout=(2, 2), size=(800, 600))","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"ðŸŽ‰ Congratulations! You have successfully finished the first part of the tutorial. Now you can continue with more concepts and options in the following sections ðŸ˜‰","category":"page"},{"location":"10-tutorial/#hull_clustering","page":"Tutorial","title":"Hull Clustering with Blended Representative Periods","text":"","category":"section"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"The function cluster! has several keyword arguments that can be used to customize the clustering process:","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"using InteractiveUtils # hide\ndocstring = string(@doc cluster!) #hide\ndocstring = match(r\"\\*\\*Keyword arguments\\*\\*.*\"s, docstring) #hide\nprintln(docstring.match) #hide","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"Alternatively, you can use the help mode in Julia REPL by typing ?cluster! to see all the available keyword arguments and their descriptions.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"As you can see, there are several keyword arguments that can be combined to explore different clustering strategies. Our proposed method is the Hull Clustering with Blended Representative Periods, which can be activated by setting the following keyword arguments:","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"method = :convex_hull\ndistance = Distances.CosineDist()\nweight_type = :convex","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"You can read more about the proposed method in the Concepts section.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"So, let's cluster again using the proposed method:","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"for table_name in (          # hide\n    \"rep_periods_data\",      # hide\n    \"rep_periods_mapping\",   # hide\n    \"profiles_rep_periods\",  # hide\n    \"timeframe_data\",        # hide\n)                            # hide\n    DuckDB.query(connection, \"DROP TABLE IF EXISTS $table_name\") # hide\nend                          # hide\nusing Distances\nclusters = cluster!(connection,\n                    period_duration,\n                    num_rps;\n                    method = :convex_hull,\n                    distance = Distances.CosineDist(),\n                    weight_type = :convex\n                    )\n\nnice_query(\"SHOW tables\")","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"As you can see, the output tables names are the same as before, but the results will be different. You can explore the results again using SQL queries or export them to CSV or Parquet files using DuckDB's writers.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"Let's plot again the profiles in the Netherlands, but this time using the clustered profiles with the hull clustering method:","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"df = nice_query(\"\"\"\n    SELECT *\n    FROM profiles_rep_periods\n    WHERE profile_name LIKE 'NED_%'\n    ORDER BY profile_name, timestep\n\"\"\")\nrep_periods = unique(df.rep_period)\nplots = []\n\nfor rp in rep_periods\n    df_rp = filter(row -> row.rep_period == rp, df)\n    p = plot(size=(400, 300), title=\"Hull Clustering RP $rp\")\n\n    for group in groupby(df_rp, :profile_name)\n        name = group.profile_name[1]\n        plot!(p, group.timestep, group.value, label=name)\n    end\n\n    show_legend = (rp == rep_periods[1])\n    plot!(p,\n          xlabel=\"Timestep\",\n          ylabel=\"Value\",\n          xticks=0:2:period_duration,\n          xlim=(1, period_duration),\n          ylim=(0, 1),\n          legend=show_legend ? :topleft : false,\n          legendfontsize=6\n         )\n    push!(plots, p)\nend\n\nplot(plots..., layout=(2, 2), size=(800, 600))","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"The first difference you may notice is that the representative periods (RPs) obtained with hull clustering are more extreme than those obtained with the default method. This is because hull clustering selects RPs that are more likely to be constraint-binding in an optimization model.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"tip: The Projected gradient descent parameters\nThe parameters niters and learning_rate tell for how many iterations to run the descent and by how much to adjust the weights in each iterations. More iterations make the method slower but produce better results. Larger learning rate makes the method converge faster but in a less stable manner (i.e., weights might start going up and down a lot from iteration to iteration). Sometimes you need to find the right balance for yourself. In general, if the weights produced by the method look strange, try decreasing the learning rate and/or increasing the number of iterations.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"For more details on the comparison of clustering methods please refer to the Scientific References section.","category":"page"},{"location":"10-tutorial/#Clustering-by","page":"Tutorial","title":"Clustering by","text":"","category":"section"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"TulipaClustering.jl clusters by default using the columns year, i.e., it will create representative periods for each year in the input data. The total number of representative periods will be num_rps * number_of_years. This is useful when the profiles have a strong seasonal component that changes from year to year.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"However, sometimes the user might want to cluster by other columns, e.g., scenario or region, or even by multiple columns, e.g., year and scenario. The package allows to cluster by different columns by passing a custom ProfilesTableLayout to cluster!.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"warning: Required\nThe cols_to_groupby argument in ProfilesTableLayout is a vector of symbols, i.e., cols_to_groupby = [:year, :scenario].","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"note: The number of representative periods\nWhen clustering by multiple columns, the total number of representative periods will be num_rps * number_of_unique_combinations_of_groupby_columns. For example, if the input data has 3 unique years and 2 unique scenarios, and the user wants to cluster by year and scenario, then the total number of representative periods will be num_rps * 3 * 2 = num_rps * 6.","category":"page"},{"location":"10-tutorial/#custom_layout","page":"Tutorial","title":"Using a Custom Layout","text":"","category":"section"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"Let's say that you have a table that uses different names for the columns of your data. For example, let's rename the column timestep to hour in the profiles table.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"DuckDB.query(\n  connection,\n  \"ALTER TABLE profiles\n   RENAME COLUMN timestep to hour;\n  \",\n)\n\nnice_query(\"FROM profiles LIMIT 10\")","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"In this case, you can use the custom column name by passing a ProfilesTableLayout to cluster!.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"The layout names will also be preserved in the output tables. Below we cluster again, but ask passing the information to use hour instead of the default timestep:","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"for table_name in (          # hide\n    \"rep_periods_data\",      # hide\n    \"rep_periods_mapping\",   # hide\n    \"profiles_rep_periods\",  # hide\n    \"timeframe_data\",        # hide\n)                            # hide\n    DuckDB.query(connection, \"DROP TABLE IF EXISTS $table_name\") # hide\nend                          # hide\n\nlayout = TulipaClustering.ProfilesTableLayout(; timestep = :hour)\nclusters = cluster!(connection, period_duration, num_rps; layout)\n\nnice_query(\"FROM profiles_rep_periods LIMIT 10\")","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"Notice the column hour in the output above (instead of timestep).","category":"page"},{"location":"10-tutorial/#Extra-Functions-in-High-level-API/DuckDB-API","page":"Tutorial","title":"Extra Functions in High level API/DuckDB API","text":"","category":"section"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"The high-level API of TulipaClustering focuses on using TulipaClustering as part of the Tulipa workflow. This API consists of three main functions: cluster!, transform_wide_to_long!, and dummy_cluster!. These functions are designed to work with DuckDB connections and tables, making it easy to integrate clustering into your data processing pipeline. In the previous sections, we have already covered the usage of cluster! and transform_wide_to_long!. In this section, we will explore the third function, dummy_cluster!, which is useful for testing and debugging purposes.","category":"page"},{"location":"10-tutorial/#Dummy-Clustering","page":"Tutorial","title":"Dummy Clustering","text":"","category":"section"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"A dummy cluster will essentially ignore the clustering, but it will create the necessary tables that are often used for the next steps in the Tulipa workflow.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"for table_name in (          # hide\n    \"rep_periods_data\",      # hide\n    \"rep_periods_mapping\",   # hide\n    \"profiles_rep_periods\",  # hide\n    \"timeframe_data\",        # hide\n)                            # hide\n    DuckDB.query(connection, \"DROP TABLE IF EXISTS $table_name\") # hide\nend                          # hide\n\nclusters = dummy_cluster!(connection; layout)\n\nnice_query(\"FROM rep_periods_data LIMIT 10\")","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"In this case the function created a single representative period for all the data.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"Notice that we passed the layout argument to dummy_cluster! to ensure that the output tables have the correct column names, since we renamed the timestep column to hour in the previous section.","category":"page"},{"location":"10-tutorial/#Transform-a-wide-profiles-table-into-a-long-table","page":"Tutorial","title":"Transform a wide profiles table into a long table","text":"","category":"section"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"warning: Required\nThe long table format is a requirement of TulipaClustering, even for the dummy clustering example.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"A long table is a table where the profile names are stacked in a column with the corresponding values in a separate column. However, sometimes the input data is in a wide format, i.e., each profile is in a separate column.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"In those cases, you can use the function transform_wide_to_long! to transform a wide table into a long table. You need to provide the connection to DuckDB, the name of the source table (the wide table) and the name of the target table (the long table that will be created).","category":"page"},{"location":"10-tutorial/#Low-level-API","page":"Tutorial","title":"Low level API","text":"","category":"section"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"The cluster! function is a wrapper around the low-level clustering functions. It simplifies the process of clustering by handling the creation of temporary tables and managing the clustering workflow.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"However, if you want to have more control over the clustering process, you can use the low-level functions directly. The low-level API consists of the following functions:","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"split_into_periods!: Splits the profiles into periods based on the specified period duration.\nfind_representative_periods: Finds the representative periods using the specified clustering method.\nfit_rep_period_weights!: Fits the weights for the representative periods to map them to the original periods.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"At the end of the clustering process, you will get a TulipaClustering.ClusteringResult struct that contains the detailed results of the clustering process:","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"profiles is a dataframe with profiles for RPs,\nweight_matrix is a matrix of weights of RPs in blended periods,\nclustering_matrix and rp_matrix are matrices of profile data for each base and representative period (useful to keep for the next step, but you should not need these unless you want to do some extra math here)\nauxiliary_data contains some extra data that was generated during the clustering process and is generally not interesting to the user who is not planning to interact with the clustering method on a very low level. For example, if you use the k-medoids method, the auxiliary_data will contain the indices of the medoids in the original data.","category":"page"},{"location":"10-tutorial/","page":"Tutorial","title":"Tutorial","text":"So, although we recommend using the high-level API for most use cases, you can use the low-level functions if you need more control over the clustering process.","category":"page"},{"location":"91-developer/#dev_docs","page":"Developer documentation","title":"Developer documentation","text":"","category":"section"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"note: Contributing guidelines\nIf you haven't, please read the Contributing guidelines first.","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"If you want to make contributions to this package that involves code, then this guide is for you.","category":"page"},{"location":"91-developer/#First-time-clone","page":"Developer documentation","title":"First time clone","text":"","category":"section"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"tip: If you have writing rights\nIf you have writing rights, you don't have to fork. Instead, simply clone and skip ahead. Whenever upstream is mentioned, use origin instead.","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"If this is the first time you work with this repository, follow the instructions below to clone the repository.","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"Fork this repo\nClone your repo (this will create a git remote called origin)\nAdd this repo as a remote:\ngit remote add upstream https://github.com/TulipaEnergy/TulipaClustering.jl","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"This will ensure that you have two remotes in your git: origin and upstream. You will create branches and push to origin, and you will fetch and update your local main branch from upstream.","category":"page"},{"location":"91-developer/#Linting-and-formatting","page":"Developer documentation","title":"Linting and formatting","text":"","category":"section"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"Install a plugin on your editor to use EditorConfig. This will ensure that your editor is configured with important formatting settings.","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"We use https://pre-commit.com to run the linters and formatters. In particular, the Julia code is formatted using JuliaFormatter.jl, so please install it globally first:","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"julia> # Press ]\npkg> activate\npkg> add JuliaFormatter","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"To install pre-commit, we recommend using pipx as follows:","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"# Install pipx following the link\npipx install pre-commit","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"With pre-commit installed, activate it as a pre-commit hook:","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"pre-commit install","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"To run the linting and formatting manually, enter the command below:","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"pre-commit run -a","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"Now, you can only commit if all the pre-commit tests pass.","category":"page"},{"location":"91-developer/#Testing","page":"Developer documentation","title":"Testing","text":"","category":"section"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"As with most Julia packages, you can just open Julia in the repository folder, activate the environment, and run test:","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"julia> # press ]\npkg> activate .\npkg> test","category":"page"},{"location":"91-developer/#Working-on-a-new-issue","page":"Developer documentation","title":"Working on a new issue","text":"","category":"section"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"We try to keep a linear history in this repo, so it is important to keep your branches up-to-date.","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"Fetch from the remote and fast-forward your local main\ngit fetch upstream\ngit switch main\ngit merge --ff-only upstream/main\nBranch from main to address the issue (see below for naming)\ngit switch -c 42-add-answer-universe\nPush the new local branch to your personal remote repository\ngit push -u origin 42-add-answer-universe\nCreate a pull request to merge your remote branch into the org main.","category":"page"},{"location":"91-developer/#Branch-naming","page":"Developer documentation","title":"Branch naming","text":"","category":"section"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"If there is an associated issue, add the issue number.\nIf there is no associated issue, and the changes are small, add a prefix such as \"typo\", \"hotfix\", \"small-refactor\", according to the type of update.\nIf the changes are not small and there is no associated issue, then create the issue first, so we can properly discuss the changes.\nUse dash separated imperative wording related to the issue (e.g., 14-add-tests, 15-fix-model, 16-remove-obsolete-files).","category":"page"},{"location":"91-developer/#Commit-message","page":"Developer documentation","title":"Commit message","text":"","category":"section"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"Use imperative or present tense, for instance: Add feature or Fix bug.\nHave informative titles.\nWhen necessary, add a body with details.\nIf there are breaking changes, add the information to the commit message.","category":"page"},{"location":"91-developer/#Before-creating-a-pull-request","page":"Developer documentation","title":"Before creating a pull request","text":"","category":"section"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"tip: Atomic git commits\nTry to create \"atomic git commits\" (recommended reading: The Utopic Git History).","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"Make sure the tests pass.\nMake sure the pre-commit tests pass.\nFetch any main updates from upstream and rebase your branch, if necessary:\ngit fetch upstream\ngit rebase upstream/main BRANCH_NAME\nThen you can open a pull request and work with the reviewer to address any issues.","category":"page"},{"location":"91-developer/#Building-and-viewing-the-documentation-locally","page":"Developer documentation","title":"Building and viewing the documentation locally","text":"","category":"section"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"Following the latest suggestions, we recommend using LiveServer to build the documentation. Here is how you do it:","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"Run julia --project=docs to open Julia in the environment of the docs.\nIf this is the first time building the docs\nPress ] to enter pkg mode\nRun pkg> dev . to use the development version of your package\nPress backspace to leave pkg mode\nRun julia> using LiveServer\nRun julia> servedocs(launch_browser=true)","category":"page"},{"location":"91-developer/#Making-a-new-release","page":"Developer documentation","title":"Making a new release","text":"","category":"section"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"To create a new release, you can follow these simple steps:","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"Create a branch release-x.y.z\nUpdate version in Project.toml\nUpdate the CHANGELOG.md:\nRename the section \"Unreleased\" to \"[x.y.z] - yyyy-mm-dd\" (i.e., version under brackets, dash, and date in ISO format)\nAdd a new section on top of it named \"Unreleased\"\nAdd a new link in the bottom for version \"x.y.z\"\nChange the \"[unreleased]\" link to use the latest version - end of line, vx.y.z ... HEAD.\nCreate a commit \"Release vx.y.z\", push, create a PR, wait for it to pass, merge the PR.\nGo back to main screen and click on the latest commit (link: https://github.com/TulipaEnergy/TulipaClustering.jl/commit/main)\nAt the bottom, write @JuliaRegistrator register","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"After that, you only need to wait and verify:","category":"page"},{"location":"91-developer/","page":"Developer documentation","title":"Developer documentation","text":"Wait for the bot to comment (should take < 1m) with a link to a PR to the registry\nFollow the link and wait for a comment on the auto-merge\nThe comment should said all is well and auto-merge should occur shortly\nAfter the merge happens, TagBot will trigger and create a new GitHub tag. Check on https://github.com/TulipaEnergy/TulipaClustering.jl/releases\nAfter the release is create, a \"docs\" GitHub action will start for the tag.\nAfter it passes, a deploy action will run.\nAfter that runs, the stable docs should be updated. Check them and look for the version number.","category":"page"},{"location":"95-reference/#reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"95-reference/","page":"Reference","title":"Reference","text":"Pages = [\"95-reference.md\"]","category":"page"},{"location":"95-reference/#TulipaClustering.AuxiliaryClusteringData","page":"Reference","title":"TulipaClustering.AuxiliaryClusteringData","text":"Structure to hold the time series used in clustering together with some summary statistics on the data.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#TulipaClustering.ClusteringResult","page":"Reference","title":"TulipaClustering.ClusteringResult","text":"Structure to hold the clustering result.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#TulipaClustering.DataValidationException","page":"Reference","title":"TulipaClustering.DataValidationException","text":"DataValidationException\n\nException related to data validation of the Tulipa Energy Model input data.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#TulipaClustering.ProfilesTableLayout","page":"Reference","title":"TulipaClustering.ProfilesTableLayout","text":"ProfilesTableLayout(;key = value, ...)\nProfilesTableLayout(path; ...)\n\nStructure to hold the profiles input data table layout. Column names in the layout are defined by default.\n\nIf path is passed, it is expected to be a string pointing to a TOML file with a key = value list of parameters. Explicit keyword arguments take precedence.\n\nParameters\n\nvalue::Symbol = :value: The column name with the profile values.\ntimestep::Symbol = :timestep: The column name with the time steps in the profile.\nperiod::Symbol = :period: The column name with the period number in the profile.\nyear::Symbol = :year: The column name with the year of the profile.\nscenario::Symbol = :scenario: The column name with the scenario of the profile.\ncols_to_groupby::Vector{Symbol} = [:year]: The column names to group by when performing clustering on groups of profiles separately. If empty, no grouping is done.\n\n\n\n\n\n","category":"type"},{"location":"95-reference/#TulipaClustering._combine_group_profiles-Tuple{Dict{DataFrames.GroupKey{DataFrames.GroupedDataFrame{DataFrames.DataFrame}}, TulipaClustering.ClusteringResult}, Int64}","page":"Reference","title":"TulipaClustering._combine_group_profiles","text":"A function to offset representative period indices so that groups have disjoint repperiod ranges. For group index g, newrepperiod = oldrepperiod + offset given by _repperiodoffset(nrp, g).\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering._combine_rep_periods_data-Tuple{Dict{DataFrames.GroupKey{DataFrames.GroupedDataFrame{DataFrames.DataFrame}}, TulipaClustering.ClusteringResult}, Int64}","page":"Reference","title":"TulipaClustering._combine_rep_periods_data","text":"A function to combine repperiodsdata from different groups. For group index g, newrepperiod = oldrepperiod + offset given by repperiodoffset(nrp, g). In addition, the group key columns are added to the resulting dataframe.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering._combine_timeframe_data-Tuple{Dict{DataFrames.GroupKey{DataFrames.GroupedDataFrame{DataFrames.DataFrame}}, TulipaClustering.ClusteringResult}}","page":"Reference","title":"TulipaClustering._combine_timeframe_data","text":"A function to combine timeframe_data from different groups. Creates timeframe data with period information for each group. In addition, the group key columns are added to the resulting dataframe.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering._combine_weight_matrices-Tuple{Dict{DataFrames.GroupKey{DataFrames.GroupedDataFrame{DataFrames.DataFrame}}, TulipaClustering.ClusteringResult}, Int64}","page":"Reference","title":"TulipaClustering._combine_weight_matrices","text":"A function to combine weight matrices from different groups. For group index g, newrepperiod = oldrepperiod + offset given by repperiodoffset(nrp, g). In addition, the group key columns are added to the resulting dataframe.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering._rep_period_offset-Tuple{Int64, Int64}","page":"Reference","title":"TulipaClustering._rep_period_offset","text":"A helper function to compute the rep_period offset for group indexing.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.append_period_from_source_df_as_rp!-Tuple{DataFrames.AbstractDataFrame}","page":"Reference","title":"TulipaClustering.append_period_from_source_df_as_rp!","text":"appendperiodfromsourcedfasrp!(df; sourcedf, period, rp, keycolumns, layout = ProfilesTableLayout())\n\nExtracts a period with index period from source_df and appends it as a representative period with index rp to df, using key_columns as keys. Respects custom column names via layout.\n\nExamples\n\nDefault layout:\n\njulia> source_df = DataFrame([:period => [1, 1, 2, 2], :timestep => [1, 2, 1, 2], :a .=> \"b\", :value => 5:8])\n4Ã—4 DataFrame\n Row â”‚ period  timestep  a       value\n     â”‚ Int64   Int64      String  Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚      1          1  b           5\n   2 â”‚      1          2  b           6\n   3 â”‚      2          1  b           7\n   4 â”‚      2          2  b           8\n\njulia> df = DataFrame([:rep_period => [1, 1, 2, 2], :timestep => [1, 2, 1, 2], :a .=> \"a\", :value => 1:4])\n4Ã—4 DataFrame\n Row â”‚ rep_period  timestep  a       value\n     â”‚ Int64       Int64      String  Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚          1          1  a           1\n   2 â”‚          1          2  a           2\n   3 â”‚          2          1  a           3\n   4 â”‚          2          2  a           4\n\njulia> TulipaClustering.append_period_from_source_df_as_rp!(df; source_df, period = 2, rp = 3, key_columns = [:timestep, :a])\n6Ã—4 DataFrame\n Row â”‚ rep_period  timestep  a       value\n     â”‚ Int64       Int64      String  Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚          1          1  a           1\n   2 â”‚          1          2  a           2\n   3 â”‚          2          1  a           3\n   4 â”‚          2          2  a           4\n   5 â”‚          3          1  b           7\n   6 â”‚          3          2  b           8\n\nCustom layout:\n\njulia> layout = ProfilesTableLayout(; period=:p, timestep=:ts, value=:val)\njulia> src = DataFrame([:p => [1,1,2,2], :ts => [1,2,1,2], :a .=> \"b\", :val => 5:8])\njulia> df = DataFrame([:rep_period => [1,1], :ts => [1,2], :a .=> \"a\", :val => [1,2]])\njulia> TulipaClustering.append_period_from_source_df_as_rp!(df; source_df = src, period = 2, rp = 3, key_columns = [:ts, :a], layout)\n4Ã—4 DataFrame\n Row â”‚ rep_period  ts    a       val\n   â”‚ Int64       Int64  String  Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚          1     1  a           1\n   2 â”‚          1     2  a           2\n   3 â”‚          3     1  b           7\n   4 â”‚          3     2  b           8\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.cluster!-Tuple{Any, Any, Any}","page":"Reference","title":"TulipaClustering.cluster!","text":"cluster!(\n    connection,\n    period_duration,\n    num_rps;\n    input_database_schema = \"\",\n    input_profile_table_name = \"profiles\",\n    database_schema = \"\",\n    drop_incomplete_last_period::Bool = false,\n    method::Symbol = :k_means,\n    distance::SemiMetric = SqEuclidean(),\n    initial_representatives::AbstractDataFrame = DataFrame(),\n    layout::ProfilesTableLayout = ProfilesTableLayout(),\n    weight_type::Symbol = :convex,\n    tol::Float64 = 1e-2,\n    clustering_kwargs = Dict(),\n    weight_fitting_kwargs = Dict(),\n)\n\nConvenience function to cluster the table named in input_profile_table_name using period_duration and num_rps. The resulting tables profiles_rep_periods, rep_periods_mapping, and rep_periods_data are loaded into connection in the database_schema, if given, and enriched with year information.\n\nThis function extracts the table (expecting columns profile_name, timestep, value), then calls split_into_periods!, find_representative_periods, fit_rep_period_weights!, and finally write_clustering_result_to_tables.\n\nArguments\n\nRequired\n\nconnection: DuckDB connection\nperiod_duration: Duration of each period, i.e., number of timesteps.\nnum_rps: Number of findrepresentativeperiods\n\nKeyword arguments\n\ninput_database_schema (default \"\"): Schema of the input tables\ninput_profile_table_name (default \"profiles\"): Default name of the profiles table inside the above schemaa\ndatabase_schema (default \"\"): Schema of the output tables\ndrop_incomplete_last_period (default false): controls how the last period is treated if it is not complete: if this parameter is set to true, the incomplete period is dropped and the weights are rescaled accordingly; otherwise, clustering is done for n_rp - 1 periods, and the last period is added as a special shorter representative period\nmethod (default :k_medoids): clustering method to use :k_means, :k_medoids, :convex_hull, :convex_hull_with_null, or :conical_hull.\ndistance (default Distances.Euclidean()): semimetric used to measure distance between data points.\ninitial_representatives initial representatives that should be   included in the clustering. The period column in the initial representatives   should be 1-indexed and the key columns should be the same as in the clustering data.   For the hull methods it will be added before clustering, for :kmeans and :kmedoids   it will be added after clustering.\nlayout (default ProfilesTableLayout()): describes the column names for period, timestep, and value in in-memory DataFrames. It does not change the SQL input table schema, which must contain profile_name, timestep, and value. Weight fitting operates on matrices and does not use layout.\nweight_type (default :dirac): the type of weights to find; possible values are:\n:dirac: each period is represented by exactly one representative   period (a one unit weight and the rest are zeros)\n:convex: each period is represented as a convex sum of the representative periods (a sum with nonnegative weights adding into one)\n:conical: each period is represented as a conical sum of the representative periods (a sum with nonnegative weights)\n:conical_bounded: each period is represented as a conical sum of the representative periods (a sum with nonnegative weights) with the total weight bounded from above by one.\ntol (default 1e-2): algorithm's tolerance; when the weights are adjusted by a value less then or equal to tol, they stop being fitted further.\nclustering_kwargs (default Dict()): Extra keyword arguments passed to find_representative_periods\nweight_fitting_kwargs (default Dict()): Extra keyword arguments passed to fit_rep_period_weights! (e.g., niters, learning_rate, adaptive_grad).\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.combine_periods!-Tuple{DataFrames.AbstractDataFrame}","page":"Reference","title":"TulipaClustering.combine_periods!","text":"combine_periods!(df; layout = ProfilesTableLayout())\n\nCombine per-period time steps into a single global timestep column in-place.\n\nGiven a long-format dataframe df with (at least) a per-period timestep column and, optionally, a period column (names provided by layout), this function rewrites the timestep column so that time becomes a single global, monotonically increasing index across all periods, then removes the original period column.\n\nPeriod length inference:\n\nThe (nominal) period duration L is inferred as the maximum value found in the per-period time-step column across the whole dataframe (NOT per period).\nEach row's global timestep is computed as (period - 1) * L + timestep.\nIf the final period is shorter than L, the resulting global time index will simply end earlier; missing intermediate global timesteps are not created.\n\nArguments:\n\ndf::AbstractDataFrame (mutated): Source data in long format.\nlayout::ProfilesTableLayout: Describes the column names for period and timestep (defaults to standard names). Pass a custom layout if your dataframe uses different symbols.\n\nBehavior & edge cases:\n\nIf the timestep column (as specified by layout) is missing, a DomainError is thrown.\nIf the period column is absent, the function is a no-op (returns immediately).\nNon-1-based or non-consecutive per-period timesteps are not validated; unusual values may result in non-contiguous or non-strictly increasing global indices.\nWorks in-place; the modified dataframe (without period) is also returned for convenience.\n\nExamples\n\nBasic usage with default layout:\n\njulia> df = DataFrame([:period => [1, 1, 2], :timestep => [1, 2, 1], :value => 1:3])\n3Ã—3 DataFrame\n Row â”‚ period  timestep  value\n     â”‚ Int64   Int64      Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚      1          1      1\n   2 â”‚      1          2      2\n   3 â”‚      2          1      3\n\njulia> TulipaClustering.combine_periods!(df)\n3Ã—2 DataFrame\n Row â”‚ timestep  value\n     â”‚ Int64      Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚         1      1\n   2 â”‚         2      2\n   3 â”‚         3      3\n\nCustom column names via a layout:\n\njulia> layout = ProfilesTableLayout(; period = :p, timestep = :ts)\njulia> df = DataFrame([:p => [1,1,2], :ts => [1,2,1], :value => 10:12])\n3Ã—3 DataFrame\n Row â”‚ p      ts   value\n     â”‚ Int64  Int64  Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚     1     1     10\n   2 â”‚     1     2     11\n   3 â”‚     2     1     12\n\njulia> TulipaClustering.combine_periods!(df; layout)\n3Ã—2 DataFrame\n Row â”‚ ts    value\n     â”‚ Int64  Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚    1     10\n   2 â”‚    2     11\n   3 â”‚    3     12\n\nNo period column (no-op):\n\njulia> df = DataFrame([:timestep => 1:3, :value => 4:6])\njulia> TulipaClustering.combine_periods!(df)\n3Ã—2 DataFrame\n Row â”‚ timestep  value\n     â”‚ Int64      Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚         1      4\n   2 â”‚         2      5\n   3 â”‚         3      6\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.df_to_matrix_and_keys-Tuple{DataFrames.AbstractDataFrame, Vector{Symbol}}","page":"Reference","title":"TulipaClustering.df_to_matrix_and_keys","text":"dftomatrixandkeys(df, key_columns; layout = ProfilesTableLayout())\n\nConverts a long-format dataframe df to a matrix, using the value/period columns from layout. Columns listed in key_columns are kept as keys.\n\nReturns (matrix::Matrix{Float64}, keys::DataFrame).\n\nExamples\n\nDefault layout:\n\njulia> df = DataFrame([:period => [1, 1, 2, 2], :timestep => [1, 2, 1, 2], :a .=> \"a\", :value => 1:4])\n4Ã—4 DataFrame\n Row â”‚ period  timestep  a       value\n     â”‚ Int64   Int64      String  Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚      1          1  a           1\n   2 â”‚      1          2  a           2\n   3 â”‚      2          1  a           3\n   4 â”‚      2          2  a           4\n\njulia> m, k = TulipaClustering.df_to_matrix_and_keys(df, [:timestep, :a]); m\n2Ã—2 Matrix{Float64}:\n 1.0  3.0\n 2.0  4.0\n\njulia> k\n2Ã—2 DataFrame\n Row â”‚ timestep  a\n     â”‚ Int64      String\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚         1  a\n   2 â”‚         2  a\n\nCustom layout:\n\njulia> layout = ProfilesTableLayout(; period=:p, timestep=:ts, value=:val)\njulia> df = DataFrame([:p => [1,1,2,2], :ts => [1,2,1,2], :a .=> \"a\", :val => 1:4])\njulia> m, k = TulipaClustering.df_to_matrix_and_keys(df, [:ts, :a]; layout); m\n2Ã—2 Matrix{Float64}:\n 1.0  3.0\n 2.0  4.0\n\njulia> k\n2Ã—2 DataFrame\n Row â”‚ ts    a\n     â”‚ Int64  String\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚    1  a\n   2 â”‚    2  a\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.dummy_cluster!-Tuple{Any}","page":"Reference","title":"TulipaClustering.dummy_cluster!","text":"dummy_cluster!(connection)\n\nConvenience function to create the necessary columns and tables when clustering is not required.\n\nThis is essentially creating a single representative period with the size of the whole profile. See cluster! for more details of what is created.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.find_auxiliary_data-Tuple{DataFrames.AbstractDataFrame}","page":"Reference","title":"TulipaClustering.find_auxiliary_data","text":"find_auxiliary_data(clustering_data; layout = ProfilesTableLayout())\n\nCalculates auxiliary data associated with clustering_data, considering custom column names via layout.\n\nReturns AuxiliaryClusteringData with:\n\nkey_columns: key columns in the dataframe\nperiod_duration: nominal duration of periods (max timestep across data)\nlast_period_duration: duration of the last period\nn_periods: total number of periods\n\nExample\n\njulia> df = DataFrame([:period => [1,1,2,2], :timestep => [1,2,1,2], :a => \"x\", :value => 10:13])\njulia> aux = TulipaClustering.find_auxiliary_data(df)\nAuxiliaryClusteringData([:timestep, :a], 2, 2, 2, nothing)\n\njulia> layout = ProfilesTableLayout(; period=:p, timestep=:ts, value=:val)\njulia> df2 = DataFrame([:p => [1,1,2,2], :ts => [1,2,1,1], :a => \"x\", :val => 10:13])\njulia> TulipaClustering.find_auxiliary_data(df2; layout)\nAuxiliaryClusteringData([:ts, :a], 2, 1, 2, nothing)\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.find_period_weights-Tuple{Int64, Int64, Int64, Bool}","page":"Reference","title":"TulipaClustering.find_period_weights","text":"find_period_weights(period_duration, last_period_duration, n_periods, drop_incomplete_periods)\n\nFinds weights of two different types of periods in the clustering data:\n\ncomplete periods: these are all of the periods with length equal to period_duration.\nincomplete last period: if last period duration is less than period_duration, it is incomplete.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.find_representative_periods-Tuple{DataFrames.AbstractDataFrame, Int64}","page":"Reference","title":"TulipaClustering.find_representative_periods","text":"findrepresentativeperiods(     clusteringdata,     nrp;     dropincompletelastperiod = false,     method = :kmeans,     distance = SqEuclidean(),     initial_representatives = DataFrame(),     layout = ProfilesTableLayout(),     kwargs...,   )\n\nFinds representative periods via data clustering. Honors custom column names via layout (defaults to (:period, :timestep, :value)).\n\nArguments\n\nclustering_data: long-format data to cluster.\nn_rp: number of representative periods to find.\ndrop_incomplete_last_period: controls how the last period is treated if it is not complete: if this parameter is set to true, the incomplete period is dropped and the weights are rescaled accordingly; otherwise, clustering is done for n_rp - 1 periods, and the last period is added as a special shorter representative period.\nmethod: clustering method to use :k_means, :k_medoids, :convex_hull, :convex_hull_with_null, or :conical_hull.\ndistance: semimetric used to measure distance between data points.\ninitial_representatives: dataframe of initial RPs. It must use the same key columns and follow the same layout as clustering_data. For hull methods the RPs are prepended before clustering; for :k_means/:k_medoids they are appended after clustering.\nlayout: ProfilesTableLayout describing the column names.\nother named arguments are forwarded to the clustering method.\n\nReturns\n\nReturns a ClusteringResult with:\n\nprofiles::DataFrame: Long-format representative profiles with columns :rep_period, layout.timestep, all key columns (auxiliary_data.key_columns), and layout.value.\nweight_matrix::SparseMatrixCSC{Float64,Int} (or dense Matrix{Float64}): rows correspond to source periods and columns to representative periods; entry (p, r) is the weight of period p assigned to representative r. If the last period is incomplete and drop_incomplete_last_period is false, it maps to its own representative column with its specific weight; if dropped, it is excluded from the rows.\nclustering_matrix::Matrix{Float64}: The feature-by-period matrix used for clustering (features are derived from layout.timestep crossed with key columns).\nrp_matrix::Matrix{Float64}: The representative profiles in matrix form (same feature layout as clustering_matrix).\nauxiliary_data::AuxiliaryClusteringData: Auxiliary metadata such as key_columns, period_duration, last_period_duration, n_periods, and (for applicable methods) medoids indices.\n\nExamples\n\nFinding two representatives using default values:\n\njulia> df = DataFrame(\n           period = kron(1:4, ones(Int, 2)),\n           timestep = repeat(1:2, 4),\n           profile = \"A\",\n           value = 1:8,\n         )\n\njulia> res = TulipaClustering.find_representative_periods(df, 2)\n\nFinding two representatives using k-medoids and a custom layout:\n\njulia> layout = ProfilesTableLayout(; period = :p, timestep = :ts, value = :val)\n\njulia> df = DataFrame(\n           p = kron(1:4, ones(Int, 2)),\n           ts = repeat(1:2, 4),\n           profile = \"A\",\n           val = 1:8,\n         )\n\njulia> res = TulipaClustering.find_representative_periods(df, 2; method = :k_medoids, layout)\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.fit_rep_period_weights!-Tuple{TulipaClustering.ClusteringResult}","page":"Reference","title":"TulipaClustering.fit_rep_period_weights!","text":"fitrepperiodweights!(weightmatrix, clusteringmatrix, rpmatrix; weight_type, tol, args...)\n\nGiven the initial weight guesses, finds better weights for convex or conical combinations of representative periods. For conical weights, it is possible to bound the total weight by one.\n\nThe arguments:\n\nclustering_result: the result of running TulipaClustering.find_representative_periods\nweight_type: the type of weights to find; possible values are:\n:convex: each period is represented as a convex sum of the representative periods (a sum with nonnegative weights adding into one)\n:conical: each period is represented as a conical sum of the representative periods (a sum with nonnegative weights)\n:conical_bounded: each period is represented as a conical sum of the representative periods (a sum with nonnegative weights) with the total weight bounded from above by one.\ntol: algorithm's tolerance; when the weights are adjusted by a value less then or equal to tol, they stop being fitted further.\nother arguments control the projected subgradient method; they are passed through to TulipaClustering.projected_subgradient_descent!.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.fit_rep_period_weights!-Tuple{Union{SparseArrays.SparseMatrixCSC{Float64, Int64}, Matrix{Float64}}, Matrix{Float64}, Matrix{Float64}}","page":"Reference","title":"TulipaClustering.fit_rep_period_weights!","text":"fitrepperiodweights!(weightmatrix, clusteringmatrix, rpmatrix; weight_type, tol, args...)\n\nGiven the initial weight guesses, finds better weights for convex or conical combinations of representative periods. For conical weights, it is possible to bound the total weight by one.\n\nThe arguments:\n\nweight_matrix: the initial guess for weights; the weights are adjusted using a projected subgradient descent method\nclustering_matrix: the matrix of raw clustering data\nrp_matrix: the matrix of raw representative period data\nweight_type: the type of weights to find; possible values are:\n:dirac: each period is represented by exactly one representative period (a one unit weight and the rest are zeros)\n:convex: each period is represented as a convex sum of the representative periods (a sum with nonnegative weights adding into one)\n:conical: each period is represented as a conical sum of the representative periods (a sum with nonnegative weights)\n:conical_bounded: each period is represented as a conical sum of the representative periods (a sum with nonnegative weights) with the total weight bounded from above by one.\ntol: algorithm's tolerance; when the weights are adjusted by a value less then or equal to tol, they stop being fitted further.\nshow_progress: if true, a progress bar will be displayed.\nother arguments control the projected subgradient method; they are passed through to TulipaClustering.projected_subgradient_descent!.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.greedy_convex_hull-Tuple{AbstractMatrix{Float64}}","page":"Reference","title":"TulipaClustering.greedy_convex_hull","text":"greedy_convex_hull(matrix; n_points, distance, initial_indices, mean_vector)\n\nGreedy method for finding n_points points in a hull of the dataset. The points   are added iteratively, at each step the point that is the furthest away from the   hull of the current set of points is found and added to the hull.\n\nmatrix: the clustering matrix\nn_points: number of hull points to find\ndistance: distance semimetric\ninitial_indices: initial points which must be added to the hull, can be nothing\nmean_vector: when adding the first point (if initial_indices is not given),   it will be chosen as the point furthest away from the mean_vector; this can be   nothing, in which case the first step will add a point furtherst away from   the centroid (the mean) of the dataset\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.matrix_and_keys_to_df-Tuple{Matrix{Float64}, DataFrames.AbstractDataFrame}","page":"Reference","title":"TulipaClustering.matrix_and_keys_to_df","text":"matrix_and_keys_to_df(matrix, keys; layout = ProfilesTableLayout())\n\nConverts a matrix matrix to a long-format dataframe with columns (:rep_period, layout.timestep, keys..., layout.value).\n\nExamples\n\nDefault layout:\n\njulia> m = [1.0 3.0; 2.0 4.0]\n2Ã—2 Matrix{Float64}:\n 1.0  3.0\n 2.0  4.0\n\njulia> k = DataFrame([:timestep => 1:2, :a .=> \"a\"])\n2Ã—2 DataFrame\n Row â”‚ timestep  a\n     â”‚ Int64      String\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚         1  a\n   2 â”‚         2  a\n\njulia> TulipaClustering.matrix_and_keys_to_df(m, k)\n4Ã—4 DataFrame\n Row â”‚ rep_period  timestep  a       value\n     â”‚ Int64       Int64      String  Float64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚          1          1  a           1.0\n   2 â”‚          1          2  a           2.0\n   3 â”‚          2          1  a           3.0\n   4 â”‚          2          2  a           4.0\n\nCustom layout:\n\njulia> layout = ProfilesTableLayout(; timestep=:ts, value=:val)\njulia> k = DataFrame([:ts => 1:2, :a .=> \"a\"])\njulia> TulipaClustering.matrix_and_keys_to_df(m, k; layout)\n4Ã—4 DataFrame\n Row â”‚ rep_period  ts    a       val\n   â”‚ Int64       Int64  String  Float64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚          1     1  a           1.0\n   2 â”‚          1     2  a           2.0\n   3 â”‚          2     1  a           3.0\n   4 â”‚          2     2  a           4.0\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.project_onto_nonnegative_orthant-Tuple{Vector{Float64}}","page":"Reference","title":"TulipaClustering.project_onto_nonnegative_orthant","text":"projectontononnegative_orthant(vector)\n\nProjects vector onto the nonnegative orthant. This projection is trivial: replace negative components of the vector with zeros.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.project_onto_simplex-Tuple{Vector{Float64}}","page":"Reference","title":"TulipaClustering.project_onto_simplex","text":"projectontosimplex(vector)\n\nProjects vector onto a unit simplex using Michelot's algorithm in Condat's accelerated implementation (2017). See Figure 2 of Condat, L. Fast projection onto the simplex and the  ball. Math. Program. 158, 575â€“585 (2016).. For the details on the meanings of v, vÌƒ, Ï and other variables, see the original paper.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.project_onto_standard_basis-Tuple{Vector{Float64}}","page":"Reference","title":"TulipaClustering.project_onto_standard_basis","text":"projectontostandard_basis(vector)\n\nProjects vector onto the standard basis. This projection is trivial: replace all components of the vector with zeros, except for the largest one, which is replaced with one.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.projected_subgradient_descent!-Tuple{Vector{Float64}}","page":"Reference","title":"TulipaClustering.projected_subgradient_descent!","text":"projectedsubgradientdescent!(x; gradient, projection, niters, rtol, learningrate, adaptivegrad)\n\nFits x using the projected gradient descent scheme.\n\nThe arguments:\n\nx: the value to fit\nsubgradient: the subgradient operator, that is, a function that takes vectors of the same shape as x as inputs and returns a subgradient of the loss at that point; the fitting is done to minimize the corresponding implicit loss\nprojection: the projection operator, that is, a function that, given a vector x, finds a point within some subspace that is closest to x\nniters: maximum number of projected gradient descent iterations\ntol: tolerance; when no components of x improve by more than tol, the algorithm stops\nlearning_rate: learning rate of the algorithm\nadaptive_grad: if true, the learning rate is adjusted using the adaptive gradient method, see John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive Subgradient Methods for Online Learning and Stochastic   Optimization. J. Mach. Learn. Res. 12, null (2/1/2011), 2121â€“2159.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.split_into_periods!-Tuple{DataFrames.AbstractDataFrame}","page":"Reference","title":"TulipaClustering.split_into_periods!","text":"split_into_periods!(df; period_duration=nothing, layout=ProfilesTableLayout())\n\nModifies a dataframe df by separating the time column into periods of length period_duration, respecting custom column names provided by layout.\n\nThe new data is written into two columns defined by the layout:\n\nlayout.period: the period ID\nlayout.timestep: the time step within the current period\n\nIf period_duration is nothing, then all time steps are in a single period (ID 1).\n\nExamples\n\njulia> df = DataFrame([:timestep => 1:4, :value => 5:8])\n4Ã—2 DataFrame\n Row â”‚ timestep  value\n     â”‚ Int64      Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚         1      5\n   2 â”‚         2      6\n   3 â”‚         3      7\n   4 â”‚         4      8\n\njulia> TulipaClustering.split_into_periods!(df; period_duration=2)\n4Ã—3 DataFrame\n Row â”‚ period  timestep  value\n     â”‚ Int64   Int64      Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚      1          1      5\n   2 â”‚      1          2      6\n   3 â”‚      2          1      7\n   4 â”‚      2          2      8\n\njulia> df = DataFrame([:period => [1, 1, 2], :timestep => [1, 2, 1], :value => 1:3])\n3Ã—3 DataFrame\n Row â”‚ period  timestep  value\n     â”‚ Int64   Int64      Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚      1          1      1\n   2 â”‚      1          2      2\n   3 â”‚      2          1      3\n\njulia> TulipaClustering.split_into_periods!(df; period_duration=1)\n3Ã—3 DataFrame\n Row â”‚ period  timestep  value\n     â”‚ Int64   Int64      Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚      1          1      1\n   2 â”‚      2          1      2\n   3 â”‚      3          1      3\n\njulia> TulipaClustering.split_into_periods!(df)\n3Ã—3 DataFrame\n Row â”‚ period  timestep  value\n     â”‚ Int64   Int64      Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚      1          1      1\n   2 â”‚      1          2      2\n   3 â”‚      1          3      3\n\nCustom column names via a layout:\n\njulia> layout = ProfilesTableLayout(; timestep = :time_step, period = :periods)\njulia> df = DataFrame([:time_step => 1:4, :value => 5:8])\n4Ã—2 DataFrame\n Row â”‚ time_step  value\n    â”‚ Int64      Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  1 â”‚         1      5\n  2 â”‚         2      6\n  3 â”‚         3      7\n  4 â”‚         4      8\n\njulia> TulipaClustering.split_into_periods!(df; period_duration=2, layout)\n4Ã—3 DataFrame\n Row â”‚ periods  time_step  value\n    â”‚ Int64    Int64      Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n  1 â”‚       1          1      5\n  2 â”‚       1          2      6\n  3 â”‚       2          1      7\n  4 â”‚       2          2      8\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.transform_wide_to_long!-Tuple{Any, Any, Any}","page":"Reference","title":"TulipaClustering.transform_wide_to_long!","text":"transform_wide_to_long!(\n    connection,\n    wide_table_name,\n    long_table_name;\n)\n\nConvenience function to convert a table in wide format to long format using DuckDB. Originally aimed at converting a profile table like the following:\n\n| year | timestep | name1 | name2 | â‹¯  | nameN | | â€“â€“ | â€“â€“â€“â€“ | â€“â€“- | â€“â€“- | â€“ | â€“â€“- | | 2030 |        1 |   1.0 |   2.5 | â‹¯  |   0.0 | | 2030 |        2 |   1.5 |   2.6 | â‹¯  |   0.0 | | 2030 |        3 |   2.0 |   2.6 | â‹¯  |   0.0 |\n\nTo a table like the following:\n\nyear timestep profile_name value\n2030 1 name1 1.0\n2030 2 name1 1.5\n2030 3 name1 2.0\n2030 1 name2 2.5\n2030 2 name2 2.6\n2030 3 name2 2.6\nâ‹® â‹® â‹® â‹®\n2030 1 nameN 0.0\n2030 2 nameN 0.0\n2030 3 nameN 0.0\n\nThis conversion is done using the UNPIVOT SQL command from DuckDB.\n\nKeyword arguments\n\nexclude_columns = [\"year\", \"timestep\"]: Which tables to exclude from the conversion. Note that if you have more columns that you want to exclude from the wide table, e.g., scenario, you can add them to this list, e.g., [\"scenario\", \"year\", \"timestep\"].\nname_column = \"profile_name\": Name of the new column that contains the names of the old columns\nvalue_column = \"value\": Name of the new column that holds the values from the old columns\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.validate_data!-Tuple{Any}","page":"Reference","title":"TulipaClustering.validate_data!","text":"validate_data!(connection)\n\nValidate that the required data in connection exists and is correct. Throws a DataValidationException if any error is found.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.validate_df_and_find_key_columns-Tuple{DataFrames.AbstractDataFrame}","page":"Reference","title":"TulipaClustering.validate_df_and_find_key_columns","text":"validatedfandfindkey_columns(df; layout = ProfilesTableLayout())\n\nChecks that dataframe df contains the necessary columns (as described by layout) and returns a list of columns that act as keys (i.e., unique data identifiers within different periods). Keys are all columns except layout.period and layout.value.\n\nExamples\n\nDefault column names:\n\njulia> df = DataFrame([:period => [1, 1, 2], :timestep => [1, 2, 1], :a .=> \"a\", :value => 1:3])\n3Ã—4 DataFrame\n Row â”‚ period  timestep  a       value\n     â”‚ Int64   Int64      String  Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚      1          1  a           1\n   2 â”‚      1          2  a           2\n   3 â”‚      2          1  a           3\n\njulia> TulipaClustering.validate_df_and_find_key_columns(df)\n2-element Vector{Symbol}:\n :timestep\n :a\n\nCustom column names via a layout:\n\njulia> layout = ProfilesTableLayout(; period = :p, timestep = :ts, value = :val)\njulia> df = DataFrame(p = [1, 1, 2], ts = [1, 2, 1], a = \"a\", val = 1:3)\n3Ã—4 DataFrame\n Row â”‚ p      ts   a       val\n     â”‚ Int64  Int64  String  Int64\nâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n   1 â”‚     1     1  a           1\n   2 â”‚     1     2  a           2\n   3 â”‚     2     1  a           3\n\njulia> TulipaClustering.validate_df_and_find_key_columns(df; layout)\n2-element Vector{Symbol}:\n :ts\n :a\n\nMissing columns error references layout-provided names:\n\njulia> df = DataFrame([:value => 1])\njulia> TulipaClustering.validate_df_and_find_key_columns(df)\nERROR: DomainError: DataFrame must contain columns `timestep` and `value`\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.validate_initial_representatives","page":"Reference","title":"TulipaClustering.validate_initial_representatives","text":"validate_initial_representatives(\n  initial_representatives,\n  clustering_data,\n  aux_clustering,\n  last_period_excluded,\n  n_rp;\n  layout = ProfilesTableLayout()\n)\n\nValidates that initial_representatives is compatible with clustering_data for use in find_representative_periods, considering custom column names via layout. Checks include:\n\nKey columns match between initial representatives and clustering data.\nInitial representatives do not contain an incomplete last period.\nBoth dataframes have the same set of keys (no extra/missing keys).\nThe number of periods in initial_representatives does not exceed n_rp (adjusted for last_period_excluded).\n\nExamples\n\njulia> df = DataFrame([:period => [1,1,2,2], :timestep => [1,2,1,2], :zone .=> \"A\", :value => 10:13])\njulia> aux = TulipaClustering.find_auxiliary_data(df)\njulia> init = DataFrame([:period => [1,1], :timestep => [1,2], :zone .=> \"A\", :value => [10, 11]])\njulia> TulipaClustering.validate_initial_representatives(init, df, aux, false, 2)\n\nCustom layout:\n\njulia> layout = ProfilesTableLayout(; period=:p, timestep=:ts, value=:val)\njulia> df2 = DataFrame([:p => [1,1,2,2], :ts => [1,2,1,2], :zone .=> \"A\", :val => 10:13])\njulia> aux2 = TulipaClustering.find_auxiliary_data(df2; layout)\njulia> init2 = DataFrame([:p => [1,1], :ts => [1,2], :zone .=> \"A\", :val => [10, 11]])\njulia> TulipaClustering.validate_initial_representatives(init2, df2, aux2, false, 2; layout)\n\n\n\n\n\n","category":"function"},{"location":"95-reference/#TulipaClustering.weight_matrix_to_df-Tuple{Union{SparseArrays.SparseMatrixCSC{Float64, Int64}, Matrix{Float64}}}","page":"Reference","title":"TulipaClustering.weight_matrix_to_df","text":"weight_matrix_to_df(weights)\n\nConverts a weight matrix from a (sparse) matrix, which is more convenient for internal computations, to a dataframe, which is better for saving into a file. Zero weights are dropped to avoid cluttering the dataframe.\n\n\n\n\n\n","category":"method"},{"location":"95-reference/#TulipaClustering.write_clustering_result_to_tables-Tuple{Any, TulipaClustering.ClusteringResult}","page":"Reference","title":"TulipaClustering.write_clustering_result_to_tables","text":"write_clustering_result_to_tables(\n  connection,\n  clustering_result;\n  database_schema=\"\",\n  layout=ProfilesTableLayout()\n)\n\nWrites a TulipaClustering.ClusteringResult into DuckDB tables in connection.\n\n\n\n\n\n","category":"method"},{"location":"80-scientific-references/#scientific-refs","page":"Scientific References","title":"Scientific References","text":"","category":"section"},{"location":"80-scientific-references/","page":"Scientific References","title":"Scientific References","text":"This section shows the primary scientific references used in the model.","category":"page"},{"location":"80-scientific-references/","page":"Scientific References","title":"Scientific References","text":"Neustroev, G., Tejada-Arango D. A., Morales-EspaÃ±a, G., &  de Weerdt M. M. (2025). Hull Clustering with Blended Representative Periods for Energy System Optimization Models. ArXiv. https://arxiv.org/abs/2508.21641\nKremer, L.A.A., de Weerdt, M.M., Neustroev, G., Morales-EspaÃ±a, G. (2025). Stochastic programming for energy models: A blended cross-scenario representative periods approach. Master Thesis, TU Delft - Electrical Engineering, Mathematics and Computer Science. https://resolver.tudelft.nl/uuid:0e87f306-1c92-4eec-805f-72377ed57fb2","category":"page"},{"location":"90-contributing/#contributing","page":"Contributing guidelines","title":"Contributing guidelines","text":"","category":"section"},{"location":"90-contributing/","page":"Contributing guidelines","title":"Contributing guidelines","text":"First of all, thanks for the interest!","category":"page"},{"location":"90-contributing/","page":"Contributing guidelines","title":"Contributing guidelines","text":"We welcome all kinds of contribution, including, but not limited to code, documentation, examples, configuration, issue creating, etc.","category":"page"},{"location":"90-contributing/","page":"Contributing guidelines","title":"Contributing guidelines","text":"Be polite and respectful, and follow the code of conduct.","category":"page"},{"location":"90-contributing/#Bug-reports-and-discussions","page":"Contributing guidelines","title":"Bug reports and discussions","text":"","category":"section"},{"location":"90-contributing/","page":"Contributing guidelines","title":"Contributing guidelines","text":"If you think you found a bug, feel free to open an issue. Focused suggestions and requests can also be opened as issues. Before opening a pull request, start an issue or a discussion on the topic, please.","category":"page"},{"location":"90-contributing/#Working-on-an-issue","page":"Contributing guidelines","title":"Working on an issue","text":"","category":"section"},{"location":"90-contributing/","page":"Contributing guidelines","title":"Contributing guidelines","text":"If you found an issue that interests you, comment on that issue what your plans are. If the solution to the issue is clear, you can immediately create a pull request (see below). Otherwise, say what your proposed solution is and wait for a discussion around it.","category":"page"},{"location":"90-contributing/","page":"Contributing guidelines","title":"Contributing guidelines","text":"tip: Tip\nFeel free to ping us after a few days if there are no responses.","category":"page"},{"location":"90-contributing/","page":"Contributing guidelines","title":"Contributing guidelines","text":"If your solution involves code (or something that requires running the package locally), check the developer documentation. Otherwise, you can use the GitHub interface directly to create your pull request.","category":"page"},{"location":"20-concepts/#concepts","page":"Concepts","title":"Concepts","text":"","category":"section"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"The growing integration of renewable energy sources into energy systems requires planning models to account for not only demand variability but also fluctuations in renewable availability during operational periods. Capturing this temporal detail over long planning horizons can be computationally demanding or even intractable. For instance, the following figure shows the availability profile of three technologies and four different countries for the first day of each month of the year.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"(Image: Renewable availability time series)","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"A common approach to address this challenge is to approximate the problem using a reduced set of selected periods, known as representative periods (RPs). The RPs refers to specific time periods, such as days or weeks, selected to capture the variability and characteristics of the energy system over an extended period, such as a year. The core idea is that many of the periods are similar to each other; such that the solutions are also similar and we do not have to solve all of them and get an approximation from the solutions of the RPs.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"(Image: From base periods to representative periods)","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"To simplify, let's consider a single profile, for a single year. Let's denote it as p_i, where i = 1dotsN. The clustering process consists of:","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"Split N into (let's assume equal) periods of size m = period_duration. We can rename p_i as\np_jk qquad textwhere qquad j = 1dotsm quad k = 1dotsNm\nCompute L = num_rps representative periods\nr_jell qquad textwhere qquad j = 1dotsm qquad ell = 1dotsL\nDuring computation of the representative periods, we obtained weight w_kell between the period k and the representative period ell, such that\np_jk = sum_ell = 1^L r_jell  w_kell qquad forall j = 1dotsm quad k = 1dotsNm\nThe weight w_kell maps the representative periods to the base periods (or original periods).","category":"page"},{"location":"20-concepts/#Clustering-Methods","page":"Concepts","title":"Clustering Methods","text":"","category":"section"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"Representative periods are typically chosen using clustering methods. One common approach is k-means, where the representative period values, or centroids, are calculated as the average of all base periods within the cluster. Another common method is k-medoids, in which the representative period is an actual data point from the cluster.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"The method parameter in the function cluster! allows to select :k-means and :k-medoids as clustering methods. However, for better approximation, TulipaClustering also allows three more different clustering methods to choose representative periods that form the hull of the dataset: :convex_hull, :convex_hull_with_null, and :conical_hull. Although the hull clustering can be combined with different weight types, the choice of weight type determines the kind of hull within which the original periods must lie in order to be exactly reconstructible. Specifically:","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":":convex_hull: For convex weights, the original periods must lie within the convex hull of the representative periods. This is the smallest convex set containing them.\n:convex_hull_with_null: For sub-unit conic weights, reconstruction is possible if the original periods lie within the convex hull of the representative periods and the origin (null). Intuitively, this corresponds to finding convex weights that may assign some mass to a null (zero) vector. After discarding the null, the remaining positive weights sum to less than one, hence sub-unit.\n:conical_hull: For general conic weights, the reconstruction is valid as long as the original periods lie within the conic hull of the RPs.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"We illustrate the differences between these hulls in the following figure, where each successive hull type expands the space in which the original data points can be expressed using the RPs without introducing a projection error. The figure shows the geometric interpretation of different hull types. A set of base period data (dots) is shown, and the shaded region indicates the span of each hull. Even when blended weights are used, this choice of RPs introduces projection errors. The more general the hull type is, the fewer RPs cover the dataset.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"(Image: Hull Types)","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"For more details on the hull types, check the scientific references section.","category":"page"},{"location":"20-concepts/#weight-fitting","page":"Concepts","title":"Weight Fitting","text":"","category":"section"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"After the clustering is done, each period is assigned to one representative period. We call this a \"Dirac assignment\" after the Dirac measure: a measure that is concentrated on one item (i.e., one base period is mapped into exactly one representative period).","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"(Image: Dirac assignment)","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"TulipaClustering supports blended weights for representative periods, meaning that the weigths can be positive fractional numbers.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"(Image: Blended weights)","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"To produce these, we use projected gradient descent. For more details on the blended weights, check the scientific references section.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"The weight_type parameter in the function cluster! allows to select different ways to select the weights:","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":":conical weights are positive. The projection is onto a conic hull of the RPs.\n:conical_bounded also known as sub-unit conic, weights are positive, add at most into one. The projection is onto a convex hull of the RPs.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"and the origin.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":":convex weights are positive, add into one. The projection is onto a convex hull of the RPs.\n:dirac one unit weight and the rest are zeros. Periods are projected onto a discrete set of representative periods.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"The order here is from less restrictive to more restrictive.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"The following figure shows the projection errors when approximating base period data using different weight types. Orange areas show the spaces of all points which can be represented without introducing a projection error. Errors decrease from left to right as we move from a discrete Dirac to more general weight types.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"(Image: Weight Types)","category":"page"},{"location":"20-concepts/#Euclidean-Distance-vs-Dissimilarity","page":"Concepts","title":"Euclidean Distance vs Dissimilarity","text":"","category":"section"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"The distance parameter in the function cluster! defines the metric used to measure how different the datapoints are. The parameter recieves any metric from the package Distances.jl. By default it uses, euclidean distance, meaning that we seek the closest point in the convex hull by calculating the absolute distance. For instance, in the following figure, both points (2,3) and (3,6) is possible to find weights so that its error is smaller when projected to the hull.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"(Image: Euclidian Distance)","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"Nevertheless, when using the hull clustering, we want to measure dissimilarity so that:","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"d(ð‘Žð‘¥ ð‘ð‘¦) = d(ð‘¥ ð‘¦) quad textif quad ð‘Žð‘  â„+","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":".","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"In other words, we want to measure distance to rays, i.e., angular difference, instead of points. So, why cosine distance? because it meassures the angular distance and it remains the same no matter the magnitude of the data point:","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"d_cos(ð‘Žð‘¥ ð‘ð‘¦) = d_cos(ð‘¥ ð‘¦) quad textif quad ð‘Ž ð‘  â„+","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"(Image: Cosine Distance)","category":"page"},{"location":"20-concepts/#Clustering-Per-or-Across","page":"Concepts","title":"Clustering Per or Across","text":"","category":"section"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"The ProfilesTableLayout parameter in the function cluster! allows users to include cols_to_groupby for the clustering process. By default, all profiles will be clustered by the column :year, meaning that the representatives will be calculated per year. We recommend this approach because it is expected that renewable profiles will change over time due to advancements in technology. However, if the user prefers to have representative periods across multiple years, they simply need to provide an empty vector for cols_to_groupby in the ProfilesTableLayout.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"In addition, if the profiles to cluster have the column :scenario (or similar name), it can be added to the cols_to_groupby parameter in order to obtain representative periods per scenario. If the column is in the input profiles, but it is not included in the columns to group by, then by default the representative periods will be calculated across the scenario. In the following sections, we discuss more on each case.","category":"page"},{"location":"20-concepts/#Per-Scenario","page":"Concepts","title":"Per Scenario","text":"","category":"section"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"In this approach, representative periods are chosen separately for each scenario. This involves applying the steps of normalization, selection, and weight calculation to each scenario individually. As a result, each scenario has its own set of representative periods (RPs) that capture all periods within that scenario.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"The following figure illustrates the concept of scenario-specific representative periods. For instance, the high scenario has its own representative periods labeled RPs High 1 and High 2, the medium scenario has RPs Medium 1 and Medium 2, and the low scenario features RPs Low 1 and Low 2. These representative periods are used to approximate the original periods within each scenario.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"(Image: per-scenario)","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"One advantage of this approach is that the clustering task is performed on smaller, more homogeneous sets. However, this separation also means that similar patterns across different scenarios may be ignored. As a result, the union of all representatives, may include redundant or highly similar periods that increase the model size without adding new information.","category":"page"},{"location":"20-concepts/#Across-Scenarios","page":"Concepts","title":"Across Scenarios","text":"","category":"section"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"To better capture the overall structure of the full scenario space, we propose to calculate the representative across scenarios. Here, representative periods are selected from the combined set of periods across all scenarios, resulting in a single, scenario independent set of RPs. This approach allows us to identify a smaller set of representative periods that generalizes well across different scenarios, reducing redundancy and potentially improving model compactness.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"The key idea is to perform clustering on the full joint set of scenarios. The selection process thus considers the joint variability in demand and availability across all scenarios. This enables the model to reuse the same representative periods in multiple scenarios, rather than duplicating similar patterns. In this approach, the weights reflect how many original periods across all scenarios are best represented by each RP.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"The following figure illustrates the concept of representative periods across scenarios. Here, representative periods 1 to 6 are selected from the combined set of periods across all scenarios. These representative periods are then used to approximate the original periods in each scenario.","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"(Image: across-scenarios)","category":"page"},{"location":"20-concepts/","page":"Concepts","title":"Concepts","text":"An advantage of this approach is its ability to minimize redundancy by recognizing similarities between periods in different scenarios. This can lead to a more efficient representation of uncertainty, especially when common temporal patterns exist across the scenario set. However, it also requires more computational effort during the selection phase.","category":"page"},{"location":"#Welcome","page":"Welcome","title":"Welcome","text":"","category":"section"},{"location":"","page":"Welcome","title":"Welcome","text":"The TulipaClustering.jl package is a Julia package for finding representative periods (e.g., hours, days, or weeks) and their weights based on time series profiles for the energy sector (e.g., demand, availability, hydro inflows). The package uses DuckDB to handle the time series input data, then uses the parameter definition in the model and the main function cluster!, and exports the results to DuckDB again. The user can export the results to other formats, e.g., CSV, if needed.","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"(Image: TulipaClustering.jl overview)","category":"page"},{"location":"#What-is-the-Novelty-in-this-Package?","page":"Welcome","title":"What is the Novelty in this Package?","text":"","category":"section"},{"location":"","page":"Welcome","title":"Welcome","text":"This method employs a novel approach known as hull clustering with blended representative periods (RPs), which improves upon traditional clustering-based methods in two significant ways.","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"First, instead of selecting typical cluster centers, such as centroids or medoids, as RPs, the TulipaClustering hull methods utilize extreme points that are more likely to be constraint-binding.","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"Second, it represents base periods, or non-representative periods, as weighted combinations of RPs, such as convex or conic blends. This methods allows for a more accurate approximation of the entire time horizon using fewer representative periods.","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"One example of the improvements achieved by using this package to find representative periods is illustrated in the figure below. We compare the results from the energy system model TulipaEnergyModel.jl after applying TulipaClustering.jl to obtain the representative periods, using both the traditional setup and the hull clustering with blended RPs. The results demonstrate that hull clustering with blended RPs can effectively represent seasonal storageâ€”such as the hydro reservoirs in Norwayâ€”while achieving lower regret (i.e., less approximation error), requiring fewer representatives and less time.","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"(Image: Norway's hydro reservoir results)","category":"page"},{"location":"","page":"Welcome","title":"Welcome","text":"note: Can I use `TulipaClustering.jl` with other energy system optimization models?\nYes, you can ðŸ˜ Thanks to our DuckDB interface for inputs and outputs, the results can be exported to several formats, and as long as your energy system optimization model is able to use representative periods in its formulation, then you are ready to match the output of TulipaClustering.jl to your model and run your optimization. Have fun!","category":"page"},{"location":"#license","page":"Welcome","title":"License","text":"","category":"section"},{"location":"","page":"Welcome","title":"Welcome","text":"This content is released under the Apache License 2.0 License.","category":"page"},{"location":"#Contributors","page":"Welcome","title":"Contributors","text":"","category":"section"},{"location":"","page":"Welcome","title":"Welcome","text":"<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->\n<!-- prettier-ignore-start -->\n<!-- markdownlint-disable -->\n<table>\n  <tbody>\n    <tr>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/greg-neustroev\"><img src=\"https://avatars.githubusercontent.com/u/32451432?v=4?s=100\" width=\"100px;\" alt=\"Greg Neustroev\"/><br /><sub><b>Greg Neustroev</b></sub></a><br /><a href=\"#code-greg-neustroev\" title=\"Code\">ðŸ’»</a> <a href=\"#doc-greg-neustroev\" title=\"Documentation\">ðŸ“–</a> <a href=\"#maintenance-greg-neustroev\" title=\"Maintenance\">ðŸš§</a> <a href=\"#review-greg-neustroev\" title=\"Reviewed Pull Requests\">ðŸ‘€</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/g-moralesespana\"><img src=\"https://avatars.githubusercontent.com/u/42405171?v=4?s=100\" width=\"100px;\" alt=\"GermÃ¡n Morales\"/><br /><sub><b>GermÃ¡n Morales</b></sub></a><br /><a href=\"#ideas-g-moralesespana\" title=\"Ideas, Planning, & Feedback\">ðŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://abelsiqueira.com\"><img src=\"https://avatars.githubusercontent.com/u/1068752?v=4?s=100\" width=\"100px;\" alt=\"Abel Soares Siqueira\"/><br /><sub><b>Abel Soares Siqueira</b></sub></a><br /><a href=\"#code-abelsiqueira\" title=\"Code\">ðŸ’»</a> <a href=\"#review-abelsiqueira\" title=\"Reviewed Pull Requests\">ðŸ‘€</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/datejada\"><img src=\"https://avatars.githubusercontent.com/u/12887482?v=4?s=100\" width=\"100px;\" alt=\"Diego Alejandro Tejada Arango\"/><br /><sub><b>Diego Alejandro Tejada Arango</b></sub></a><br /><a href=\"#code-datejada\" title=\"Code\">ðŸ’»</a> <a href=\"#doc-datejada\" title=\"Documentation\">ðŸ“–</a> <a href=\"#review-datejada\" title=\"Reviewed Pull Requests\">ðŸ‘€</a> <a href=\"#maintenance-datejada\" title=\"Maintenance\">ðŸš§</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/clizbe\"><img src=\"https://avatars.githubusercontent.com/u/11889283?v=4?s=100\" width=\"100px;\" alt=\"Lauren Clisby\"/><br /><sub><b>Lauren Clisby</b></sub></a><br /><a href=\"#projectManagement-clizbe\" title=\"Project Management\">ðŸ“†</a> <a href=\"#ideas-clizbe\" title=\"Ideas, Planning, & Feedback\">ðŸ¤”</a></td>\n      <td align=\"center\" valign=\"top\" width=\"14.28%\"><a href=\"https://github.com/lottekremer\"><img src=\"https://avatars.githubusercontent.com/u/119004215?v=4?s=100\" width=\"100px;\" alt=\"Lotte Kremer\"/><br /><sub><b>Lotte Kremer</b></sub></a><br /><a href=\"#code-lottekremer\" title=\"Code\">ðŸ’»</a> <a href=\"#ideas-lottekremer\" title=\"Ideas, Planning, & Feedback\">ðŸ¤”</a></td>\n    </tr>\n  </tbody>\n</table>\n\n<!-- markdownlint-restore -->\n<!-- prettier-ignore-end -->\n\n<!-- ALL-CONTRIBUTORS-LIST:END -->","category":"page"}]
}
